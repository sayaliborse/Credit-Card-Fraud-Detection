{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READING CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of normal transacation is 99.82725143693798\n",
      "percentage of fraud transacation 0.1727485630620034\n"
     ]
    }
   ],
   "source": [
    "# now let us check in the number of Percentage\n",
    "Count_Normal_transacation = len(data[data[\"Class\"]==0]) # normal transaction are repersented by 0\n",
    "Count_Fraud_transacation = len(data[data[\"Class\"]==1]) # fraud by 1\n",
    "Percentage_of_Normal_transacation = Count_Normal_transacation/(Count_Normal_transacation+Count_Fraud_transacation)\n",
    "print(\"percentage of normal transacation is\",Percentage_of_Normal_transacation*100)\n",
    "Percentage_of_Fraud_transacation= Count_Fraud_transacation/(Count_Normal_transacation+Count_Fraud_transacation)\n",
    "print(\"percentage of fraud transacation\",Percentage_of_Fraud_transacation*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training data 284807\n",
      "length of normal data 284315\n",
      "length of fraud  data 492\n"
     ]
    }
   ],
   "source": [
    "print(\"length of training data\",len(data))\n",
    "print(\"length of normal data\",len(data[data[\"Class\"]==0]))\n",
    "print(\"length of fraud  data\",len(data[data[\"Class\"]==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19',\n",
    "          'V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount']]\n",
    "Y = data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  568630\n",
      "Number of normal transcation in oversampled data 284315\n",
      "No.of fraud transcation 284315\n",
      "Proportion of Normal data in oversampled data is  0.5\n",
      "Proportion of fraud data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "os = SMOTE(random_state=0) \n",
    "columns = X.columns\n",
    "\n",
    "os_data_X,os_data_y=os.fit_sample(X,Y)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=[\"Class\"])\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of normal transcation in oversampled data\",len(os_data_y[os_data_y[\"Class\"]==0]))\n",
    "print(\"No.of fraud transcation\",len(os_data_y[os_data_y[\"Class\"]==1]))\n",
    "print(\"Proportion of Normal data in oversampled data is \",len(os_data_y[os_data_y[\"Class\"]==0])/len(os_data_X))\n",
    "print(\"Proportion of fraud data in oversampled data is \",len(os_data_y[os_data_y[\"Class\"]==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.449044</td>\n",
       "      <td>-1.176339</td>\n",
       "      <td>0.913860</td>\n",
       "      <td>-1.375667</td>\n",
       "      <td>-1.971383</td>\n",
       "      <td>-0.629152</td>\n",
       "      <td>-1.423236</td>\n",
       "      <td>0.048456</td>\n",
       "      <td>-1.720408</td>\n",
       "      <td>1.626659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387226</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.500512</td>\n",
       "      <td>0.251367</td>\n",
       "      <td>-0.129478</td>\n",
       "      <td>0.042850</td>\n",
       "      <td>0.016253</td>\n",
       "      <td>7.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.384978</td>\n",
       "      <td>0.616109</td>\n",
       "      <td>-0.874300</td>\n",
       "      <td>-0.094019</td>\n",
       "      <td>2.924584</td>\n",
       "      <td>3.317027</td>\n",
       "      <td>0.470455</td>\n",
       "      <td>0.538247</td>\n",
       "      <td>-0.558895</td>\n",
       "      <td>0.309755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125992</td>\n",
       "      <td>0.049924</td>\n",
       "      <td>0.238422</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>-0.767315</td>\n",
       "      <td>-0.492208</td>\n",
       "      <td>0.042472</td>\n",
       "      <td>-0.054337</td>\n",
       "      <td>9.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.249999</td>\n",
       "      <td>-1.221637</td>\n",
       "      <td>0.383930</td>\n",
       "      <td>-1.234899</td>\n",
       "      <td>-1.485419</td>\n",
       "      <td>-0.753230</td>\n",
       "      <td>-0.689405</td>\n",
       "      <td>-0.227487</td>\n",
       "      <td>-2.094011</td>\n",
       "      <td>1.323729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102756</td>\n",
       "      <td>-0.231809</td>\n",
       "      <td>-0.483285</td>\n",
       "      <td>0.084668</td>\n",
       "      <td>0.392831</td>\n",
       "      <td>0.161135</td>\n",
       "      <td>-0.354990</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.042422</td>\n",
       "      <td>121.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>0.460230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153197</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>27.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2.791855</td>\n",
       "      <td>-0.327771</td>\n",
       "      <td>1.641750</td>\n",
       "      <td>1.767473</td>\n",
       "      <td>-0.136588</td>\n",
       "      <td>0.807596</td>\n",
       "      <td>-0.422911</td>\n",
       "      <td>-1.907107</td>\n",
       "      <td>0.755713</td>\n",
       "      <td>1.151087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.582122</td>\n",
       "      <td>1.151663</td>\n",
       "      <td>0.222182</td>\n",
       "      <td>1.020586</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>-0.232746</td>\n",
       "      <td>-0.235557</td>\n",
       "      <td>-0.164778</td>\n",
       "      <td>-0.030154</td>\n",
       "      <td>58.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.752417</td>\n",
       "      <td>0.345485</td>\n",
       "      <td>2.057323</td>\n",
       "      <td>-1.468643</td>\n",
       "      <td>-1.158394</td>\n",
       "      <td>-0.077850</td>\n",
       "      <td>-0.608581</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.436167</td>\n",
       "      <td>0.747731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263451</td>\n",
       "      <td>0.499625</td>\n",
       "      <td>1.353650</td>\n",
       "      <td>-0.256573</td>\n",
       "      <td>-0.065084</td>\n",
       "      <td>-0.039124</td>\n",
       "      <td>-0.087086</td>\n",
       "      <td>-0.180998</td>\n",
       "      <td>0.129394</td>\n",
       "      <td>15.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.103215</td>\n",
       "      <td>-0.040296</td>\n",
       "      <td>1.267332</td>\n",
       "      <td>1.289091</td>\n",
       "      <td>-0.735997</td>\n",
       "      <td>0.288069</td>\n",
       "      <td>-0.586057</td>\n",
       "      <td>0.189380</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>-0.267975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113910</td>\n",
       "      <td>-0.024612</td>\n",
       "      <td>0.196002</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>0.103758</td>\n",
       "      <td>0.364298</td>\n",
       "      <td>-0.382261</td>\n",
       "      <td>0.092809</td>\n",
       "      <td>0.037051</td>\n",
       "      <td>12.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.436905</td>\n",
       "      <td>0.918966</td>\n",
       "      <td>0.924591</td>\n",
       "      <td>-0.727219</td>\n",
       "      <td>0.915679</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>-0.665271</td>\n",
       "      <td>-0.737980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047021</td>\n",
       "      <td>-0.194796</td>\n",
       "      <td>-0.672638</td>\n",
       "      <td>-0.156858</td>\n",
       "      <td>-0.888386</td>\n",
       "      <td>-0.342413</td>\n",
       "      <td>-0.049027</td>\n",
       "      <td>0.079692</td>\n",
       "      <td>0.131024</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-5.401258</td>\n",
       "      <td>-5.450148</td>\n",
       "      <td>1.186305</td>\n",
       "      <td>1.736239</td>\n",
       "      <td>3.049106</td>\n",
       "      <td>-1.763406</td>\n",
       "      <td>-1.559738</td>\n",
       "      <td>0.160842</td>\n",
       "      <td>1.233090</td>\n",
       "      <td>0.345173</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.196848</td>\n",
       "      <td>-0.503600</td>\n",
       "      <td>0.984460</td>\n",
       "      <td>2.458589</td>\n",
       "      <td>0.042119</td>\n",
       "      <td>-0.481631</td>\n",
       "      <td>-0.621272</td>\n",
       "      <td>0.392053</td>\n",
       "      <td>0.949594</td>\n",
       "      <td>46.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.492936</td>\n",
       "      <td>-1.029346</td>\n",
       "      <td>0.454795</td>\n",
       "      <td>-1.438026</td>\n",
       "      <td>-1.555434</td>\n",
       "      <td>-0.720961</td>\n",
       "      <td>-1.080664</td>\n",
       "      <td>-0.053127</td>\n",
       "      <td>-1.978682</td>\n",
       "      <td>1.638076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.387910</td>\n",
       "      <td>-0.177650</td>\n",
       "      <td>-0.175074</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.295814</td>\n",
       "      <td>0.332931</td>\n",
       "      <td>-0.220385</td>\n",
       "      <td>0.022298</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.694885</td>\n",
       "      <td>-1.361819</td>\n",
       "      <td>1.029221</td>\n",
       "      <td>0.834159</td>\n",
       "      <td>-1.191209</td>\n",
       "      <td>1.309109</td>\n",
       "      <td>-0.878586</td>\n",
       "      <td>0.445290</td>\n",
       "      <td>-0.446196</td>\n",
       "      <td>0.568521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138334</td>\n",
       "      <td>-0.295583</td>\n",
       "      <td>-0.571955</td>\n",
       "      <td>-0.050881</td>\n",
       "      <td>-0.304215</td>\n",
       "      <td>0.072001</td>\n",
       "      <td>-0.422234</td>\n",
       "      <td>0.086553</td>\n",
       "      <td>0.063499</td>\n",
       "      <td>231.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.962496</td>\n",
       "      <td>0.328461</td>\n",
       "      <td>-0.171479</td>\n",
       "      <td>2.109204</td>\n",
       "      <td>1.129566</td>\n",
       "      <td>1.696038</td>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.521502</td>\n",
       "      <td>-1.191311</td>\n",
       "      <td>0.724396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269321</td>\n",
       "      <td>0.143997</td>\n",
       "      <td>0.402492</td>\n",
       "      <td>-0.048508</td>\n",
       "      <td>-1.371866</td>\n",
       "      <td>0.390814</td>\n",
       "      <td>0.199964</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>-0.014605</td>\n",
       "      <td>34.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.166616</td>\n",
       "      <td>0.502120</td>\n",
       "      <td>-0.067300</td>\n",
       "      <td>2.261569</td>\n",
       "      <td>0.428804</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>0.241147</td>\n",
       "      <td>0.138082</td>\n",
       "      <td>-0.989162</td>\n",
       "      <td>0.922175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307169</td>\n",
       "      <td>0.018702</td>\n",
       "      <td>-0.061972</td>\n",
       "      <td>-0.103855</td>\n",
       "      <td>-0.370415</td>\n",
       "      <td>0.603200</td>\n",
       "      <td>0.108556</td>\n",
       "      <td>-0.040521</td>\n",
       "      <td>-0.011418</td>\n",
       "      <td>2.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.247491</td>\n",
       "      <td>0.277666</td>\n",
       "      <td>1.185471</td>\n",
       "      <td>-0.092603</td>\n",
       "      <td>-1.314394</td>\n",
       "      <td>-0.150116</td>\n",
       "      <td>-0.946365</td>\n",
       "      <td>-1.617935</td>\n",
       "      <td>1.544071</td>\n",
       "      <td>-0.829881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230983</td>\n",
       "      <td>1.650180</td>\n",
       "      <td>0.200454</td>\n",
       "      <td>-0.185353</td>\n",
       "      <td>0.423073</td>\n",
       "      <td>0.820591</td>\n",
       "      <td>-0.227632</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.250475</td>\n",
       "      <td>22.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.946525</td>\n",
       "      <td>-0.044901</td>\n",
       "      <td>-0.405570</td>\n",
       "      <td>-1.013057</td>\n",
       "      <td>2.941968</td>\n",
       "      <td>2.955053</td>\n",
       "      <td>-0.063063</td>\n",
       "      <td>0.855546</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>0.573743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216715</td>\n",
       "      <td>-0.579526</td>\n",
       "      <td>-0.799229</td>\n",
       "      <td>0.870300</td>\n",
       "      <td>0.983421</td>\n",
       "      <td>0.321201</td>\n",
       "      <td>0.149650</td>\n",
       "      <td>0.707519</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-2.074295</td>\n",
       "      <td>-0.121482</td>\n",
       "      <td>1.322021</td>\n",
       "      <td>0.410008</td>\n",
       "      <td>0.295198</td>\n",
       "      <td>-0.959537</td>\n",
       "      <td>0.543985</td>\n",
       "      <td>-0.104627</td>\n",
       "      <td>0.475664</td>\n",
       "      <td>0.149451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.386694</td>\n",
       "      <td>-0.403639</td>\n",
       "      <td>-0.227404</td>\n",
       "      <td>0.742435</td>\n",
       "      <td>0.398535</td>\n",
       "      <td>0.249212</td>\n",
       "      <td>0.274404</td>\n",
       "      <td>0.359969</td>\n",
       "      <td>0.243232</td>\n",
       "      <td>26.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.173285</td>\n",
       "      <td>0.353498</td>\n",
       "      <td>0.283905</td>\n",
       "      <td>1.133563</td>\n",
       "      <td>-0.172577</td>\n",
       "      <td>-0.916054</td>\n",
       "      <td>0.369025</td>\n",
       "      <td>-0.327260</td>\n",
       "      <td>-0.246651</td>\n",
       "      <td>-0.046139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>0.067003</td>\n",
       "      <td>0.227812</td>\n",
       "      <td>-0.150487</td>\n",
       "      <td>0.435045</td>\n",
       "      <td>0.724825</td>\n",
       "      <td>-0.337082</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.030041</td>\n",
       "      <td>41.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.322707</td>\n",
       "      <td>-0.174041</td>\n",
       "      <td>0.434555</td>\n",
       "      <td>0.576038</td>\n",
       "      <td>-0.836758</td>\n",
       "      <td>-0.831083</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.220982</td>\n",
       "      <td>-1.071425</td>\n",
       "      <td>0.868559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.522951</td>\n",
       "      <td>-0.284376</td>\n",
       "      <td>-0.323357</td>\n",
       "      <td>-0.037710</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.559639</td>\n",
       "      <td>-0.280158</td>\n",
       "      <td>0.042335</td>\n",
       "      <td>0.028822</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.414289</td>\n",
       "      <td>0.905437</td>\n",
       "      <td>1.727453</td>\n",
       "      <td>1.473471</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>-0.200331</td>\n",
       "      <td>0.740228</td>\n",
       "      <td>-0.029247</td>\n",
       "      <td>-0.593392</td>\n",
       "      <td>-0.346188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097308</td>\n",
       "      <td>0.077237</td>\n",
       "      <td>0.457331</td>\n",
       "      <td>-0.038500</td>\n",
       "      <td>0.642522</td>\n",
       "      <td>-0.183891</td>\n",
       "      <td>-0.277464</td>\n",
       "      <td>0.182687</td>\n",
       "      <td>0.152665</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.059387</td>\n",
       "      <td>-0.175319</td>\n",
       "      <td>1.266130</td>\n",
       "      <td>1.186110</td>\n",
       "      <td>-0.786002</td>\n",
       "      <td>0.578435</td>\n",
       "      <td>-0.767084</td>\n",
       "      <td>0.401046</td>\n",
       "      <td>0.699500</td>\n",
       "      <td>-0.064738</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178023</td>\n",
       "      <td>0.013676</td>\n",
       "      <td>0.213734</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.294638</td>\n",
       "      <td>-0.395070</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>0.024220</td>\n",
       "      <td>12.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568600</th>\n",
       "      <td>-0.431850</td>\n",
       "      <td>1.740233</td>\n",
       "      <td>-1.287095</td>\n",
       "      <td>3.812569</td>\n",
       "      <td>-1.319112</td>\n",
       "      <td>-0.555231</td>\n",
       "      <td>-2.741254</td>\n",
       "      <td>-0.179773</td>\n",
       "      <td>-1.506202</td>\n",
       "      <td>-3.142770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457270</td>\n",
       "      <td>0.304943</td>\n",
       "      <td>0.196853</td>\n",
       "      <td>-0.188819</td>\n",
       "      <td>0.337820</td>\n",
       "      <td>0.576921</td>\n",
       "      <td>0.077519</td>\n",
       "      <td>0.560569</td>\n",
       "      <td>0.231904</td>\n",
       "      <td>3.386876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568601</th>\n",
       "      <td>1.141351</td>\n",
       "      <td>2.261760</td>\n",
       "      <td>-4.341890</td>\n",
       "      <td>5.415610</td>\n",
       "      <td>0.478417</td>\n",
       "      <td>-1.125233</td>\n",
       "      <td>-1.557897</td>\n",
       "      <td>0.450030</td>\n",
       "      <td>-2.287252</td>\n",
       "      <td>-2.878547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191662</td>\n",
       "      <td>0.216656</td>\n",
       "      <td>-0.410046</td>\n",
       "      <td>-0.047798</td>\n",
       "      <td>-0.634643</td>\n",
       "      <td>0.256817</td>\n",
       "      <td>0.094138</td>\n",
       "      <td>0.492474</td>\n",
       "      <td>0.263350</td>\n",
       "      <td>2.743238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568602</th>\n",
       "      <td>-5.416994</td>\n",
       "      <td>5.170464</td>\n",
       "      <td>-7.532386</td>\n",
       "      <td>7.952700</td>\n",
       "      <td>-2.700946</td>\n",
       "      <td>-1.626737</td>\n",
       "      <td>-6.248474</td>\n",
       "      <td>2.907716</td>\n",
       "      <td>-4.414663</td>\n",
       "      <td>-7.324847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261370</td>\n",
       "      <td>1.247857</td>\n",
       "      <td>0.463935</td>\n",
       "      <td>-0.111089</td>\n",
       "      <td>-0.511251</td>\n",
       "      <td>-0.144428</td>\n",
       "      <td>0.438673</td>\n",
       "      <td>-0.089150</td>\n",
       "      <td>-0.463596</td>\n",
       "      <td>0.059928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568603</th>\n",
       "      <td>-1.626548</td>\n",
       "      <td>1.004557</td>\n",
       "      <td>-1.560578</td>\n",
       "      <td>2.785502</td>\n",
       "      <td>-2.510142</td>\n",
       "      <td>-0.361643</td>\n",
       "      <td>-1.530560</td>\n",
       "      <td>0.761608</td>\n",
       "      <td>-1.435956</td>\n",
       "      <td>-3.954546</td>\n",
       "      <td>...</td>\n",
       "      <td>1.113034</td>\n",
       "      <td>0.739270</td>\n",
       "      <td>0.447762</td>\n",
       "      <td>0.534878</td>\n",
       "      <td>0.318922</td>\n",
       "      <td>0.034624</td>\n",
       "      <td>0.792849</td>\n",
       "      <td>0.449038</td>\n",
       "      <td>0.257831</td>\n",
       "      <td>317.952570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568604</th>\n",
       "      <td>-0.565370</td>\n",
       "      <td>1.312136</td>\n",
       "      <td>-3.436349</td>\n",
       "      <td>1.866344</td>\n",
       "      <td>-0.256212</td>\n",
       "      <td>-2.177116</td>\n",
       "      <td>-1.987386</td>\n",
       "      <td>0.525516</td>\n",
       "      <td>-0.687097</td>\n",
       "      <td>-4.050907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404327</td>\n",
       "      <td>0.714316</td>\n",
       "      <td>0.693659</td>\n",
       "      <td>-0.220986</td>\n",
       "      <td>-0.006995</td>\n",
       "      <td>0.386094</td>\n",
       "      <td>0.074312</td>\n",
       "      <td>0.452447</td>\n",
       "      <td>0.093326</td>\n",
       "      <td>22.499206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568605</th>\n",
       "      <td>-7.446569</td>\n",
       "      <td>-7.323783</td>\n",
       "      <td>-4.002447</td>\n",
       "      <td>3.645846</td>\n",
       "      <td>5.737345</td>\n",
       "      <td>-6.054929</td>\n",
       "      <td>-6.029529</td>\n",
       "      <td>1.537511</td>\n",
       "      <td>-0.633829</td>\n",
       "      <td>-4.021872</td>\n",
       "      <td>...</td>\n",
       "      <td>2.917522</td>\n",
       "      <td>1.189353</td>\n",
       "      <td>-0.893352</td>\n",
       "      <td>-0.292237</td>\n",
       "      <td>-0.488294</td>\n",
       "      <td>0.162431</td>\n",
       "      <td>0.411722</td>\n",
       "      <td>0.735777</td>\n",
       "      <td>-1.183909</td>\n",
       "      <td>30.754884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568606</th>\n",
       "      <td>-3.159428</td>\n",
       "      <td>3.079884</td>\n",
       "      <td>-5.377163</td>\n",
       "      <td>5.722466</td>\n",
       "      <td>-2.313808</td>\n",
       "      <td>-1.643678</td>\n",
       "      <td>-4.889622</td>\n",
       "      <td>1.027144</td>\n",
       "      <td>-2.361972</td>\n",
       "      <td>-5.323902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316850</td>\n",
       "      <td>0.870687</td>\n",
       "      <td>0.188216</td>\n",
       "      <td>0.235149</td>\n",
       "      <td>-0.229123</td>\n",
       "      <td>0.028015</td>\n",
       "      <td>0.089998</td>\n",
       "      <td>-0.234685</td>\n",
       "      <td>0.699816</td>\n",
       "      <td>25.778693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568607</th>\n",
       "      <td>-1.450912</td>\n",
       "      <td>2.135279</td>\n",
       "      <td>-1.279962</td>\n",
       "      <td>1.232791</td>\n",
       "      <td>-0.433712</td>\n",
       "      <td>-1.356919</td>\n",
       "      <td>-1.563957</td>\n",
       "      <td>-0.463728</td>\n",
       "      <td>-1.293990</td>\n",
       "      <td>-3.078211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269548</td>\n",
       "      <td>1.119449</td>\n",
       "      <td>-0.018298</td>\n",
       "      <td>-0.214961</td>\n",
       "      <td>0.148974</td>\n",
       "      <td>0.017302</td>\n",
       "      <td>-0.476409</td>\n",
       "      <td>0.479423</td>\n",
       "      <td>-0.015868</td>\n",
       "      <td>0.974453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568608</th>\n",
       "      <td>1.209434</td>\n",
       "      <td>2.577845</td>\n",
       "      <td>-5.370135</td>\n",
       "      <td>5.331441</td>\n",
       "      <td>1.262602</td>\n",
       "      <td>-1.342694</td>\n",
       "      <td>-1.068535</td>\n",
       "      <td>0.303722</td>\n",
       "      <td>-2.693402</td>\n",
       "      <td>-3.059046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215596</td>\n",
       "      <td>0.242171</td>\n",
       "      <td>-0.429575</td>\n",
       "      <td>-0.115692</td>\n",
       "      <td>0.083117</td>\n",
       "      <td>0.523828</td>\n",
       "      <td>0.177272</td>\n",
       "      <td>0.457655</td>\n",
       "      <td>0.272989</td>\n",
       "      <td>3.628299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568609</th>\n",
       "      <td>-1.438377</td>\n",
       "      <td>-3.069143</td>\n",
       "      <td>-6.433362</td>\n",
       "      <td>3.423775</td>\n",
       "      <td>-1.300889</td>\n",
       "      <td>-1.509051</td>\n",
       "      <td>0.592870</td>\n",
       "      <td>-0.255988</td>\n",
       "      <td>-1.139386</td>\n",
       "      <td>-4.148398</td>\n",
       "      <td>...</td>\n",
       "      <td>3.072016</td>\n",
       "      <td>1.277075</td>\n",
       "      <td>-0.524807</td>\n",
       "      <td>-1.475724</td>\n",
       "      <td>-0.448835</td>\n",
       "      <td>0.119610</td>\n",
       "      <td>0.110438</td>\n",
       "      <td>0.177885</td>\n",
       "      <td>0.458281</td>\n",
       "      <td>1433.966226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568610</th>\n",
       "      <td>-0.956192</td>\n",
       "      <td>1.975265</td>\n",
       "      <td>-1.937979</td>\n",
       "      <td>2.098744</td>\n",
       "      <td>-1.108404</td>\n",
       "      <td>-1.237650</td>\n",
       "      <td>-2.191654</td>\n",
       "      <td>0.881855</td>\n",
       "      <td>-1.780943</td>\n",
       "      <td>-3.396356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242237</td>\n",
       "      <td>0.562334</td>\n",
       "      <td>0.126448</td>\n",
       "      <td>-0.054446</td>\n",
       "      <td>-0.038993</td>\n",
       "      <td>0.114418</td>\n",
       "      <td>-0.125625</td>\n",
       "      <td>0.428352</td>\n",
       "      <td>0.247689</td>\n",
       "      <td>0.945247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568611</th>\n",
       "      <td>-3.189151</td>\n",
       "      <td>2.365126</td>\n",
       "      <td>-4.019560</td>\n",
       "      <td>0.494608</td>\n",
       "      <td>-2.187439</td>\n",
       "      <td>-1.725685</td>\n",
       "      <td>-3.150328</td>\n",
       "      <td>-0.977580</td>\n",
       "      <td>-0.003257</td>\n",
       "      <td>-5.104877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054859</td>\n",
       "      <td>1.825581</td>\n",
       "      <td>-0.343719</td>\n",
       "      <td>-0.155675</td>\n",
       "      <td>0.047872</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>-0.757765</td>\n",
       "      <td>-0.899771</td>\n",
       "      <td>-0.839433</td>\n",
       "      <td>86.502020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568612</th>\n",
       "      <td>-27.974616</td>\n",
       "      <td>15.650318</td>\n",
       "      <td>-29.025672</td>\n",
       "      <td>6.423893</td>\n",
       "      <td>-20.428470</td>\n",
       "      <td>-4.835199</td>\n",
       "      <td>-19.265164</td>\n",
       "      <td>18.407850</td>\n",
       "      <td>-3.663920</td>\n",
       "      <td>-7.996159</td>\n",
       "      <td>...</td>\n",
       "      <td>1.699545</td>\n",
       "      <td>1.802826</td>\n",
       "      <td>-2.073489</td>\n",
       "      <td>-1.278746</td>\n",
       "      <td>0.166239</td>\n",
       "      <td>2.009259</td>\n",
       "      <td>-0.210954</td>\n",
       "      <td>1.320494</td>\n",
       "      <td>0.386623</td>\n",
       "      <td>99.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568613</th>\n",
       "      <td>-1.255264</td>\n",
       "      <td>2.465390</td>\n",
       "      <td>-2.875635</td>\n",
       "      <td>2.367229</td>\n",
       "      <td>-1.366626</td>\n",
       "      <td>-0.947491</td>\n",
       "      <td>-3.063485</td>\n",
       "      <td>1.164484</td>\n",
       "      <td>-2.283344</td>\n",
       "      <td>-4.848886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558561</td>\n",
       "      <td>0.657560</td>\n",
       "      <td>0.092177</td>\n",
       "      <td>-0.218306</td>\n",
       "      <td>-0.512257</td>\n",
       "      <td>0.220224</td>\n",
       "      <td>0.755082</td>\n",
       "      <td>0.629784</td>\n",
       "      <td>0.247485</td>\n",
       "      <td>0.018043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568614</th>\n",
       "      <td>-1.091079</td>\n",
       "      <td>-0.973877</td>\n",
       "      <td>-0.733176</td>\n",
       "      <td>0.621101</td>\n",
       "      <td>7.879658</td>\n",
       "      <td>-4.031369</td>\n",
       "      <td>-6.123988</td>\n",
       "      <td>-0.637401</td>\n",
       "      <td>1.559775</td>\n",
       "      <td>1.237269</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.307216</td>\n",
       "      <td>1.236501</td>\n",
       "      <td>-0.066220</td>\n",
       "      <td>-10.324416</td>\n",
       "      <td>-0.304119</td>\n",
       "      <td>-2.604644</td>\n",
       "      <td>-0.455704</td>\n",
       "      <td>0.564041</td>\n",
       "      <td>0.287454</td>\n",
       "      <td>0.839537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568615</th>\n",
       "      <td>1.224977</td>\n",
       "      <td>2.560976</td>\n",
       "      <td>-5.028949</td>\n",
       "      <td>5.369525</td>\n",
       "      <td>1.097473</td>\n",
       "      <td>-1.335297</td>\n",
       "      <td>-1.129983</td>\n",
       "      <td>0.224403</td>\n",
       "      <td>-2.566532</td>\n",
       "      <td>-3.083057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275249</td>\n",
       "      <td>0.229618</td>\n",
       "      <td>-0.361572</td>\n",
       "      <td>-0.120752</td>\n",
       "      <td>-0.109754</td>\n",
       "      <td>0.520538</td>\n",
       "      <td>0.172888</td>\n",
       "      <td>0.476522</td>\n",
       "      <td>0.275160</td>\n",
       "      <td>1.440027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568616</th>\n",
       "      <td>-1.006315</td>\n",
       "      <td>1.306498</td>\n",
       "      <td>-0.478097</td>\n",
       "      <td>2.179963</td>\n",
       "      <td>-1.087580</td>\n",
       "      <td>-0.118490</td>\n",
       "      <td>-2.105637</td>\n",
       "      <td>0.641459</td>\n",
       "      <td>-1.266116</td>\n",
       "      <td>-3.216521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533261</td>\n",
       "      <td>0.461527</td>\n",
       "      <td>0.418300</td>\n",
       "      <td>-0.123274</td>\n",
       "      <td>0.165642</td>\n",
       "      <td>-0.016674</td>\n",
       "      <td>-0.079035</td>\n",
       "      <td>0.466865</td>\n",
       "      <td>0.096961</td>\n",
       "      <td>39.532234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568617</th>\n",
       "      <td>-0.691588</td>\n",
       "      <td>0.618486</td>\n",
       "      <td>1.019345</td>\n",
       "      <td>-0.217790</td>\n",
       "      <td>-0.564045</td>\n",
       "      <td>-0.609945</td>\n",
       "      <td>0.614703</td>\n",
       "      <td>0.090635</td>\n",
       "      <td>-0.152099</td>\n",
       "      <td>-1.113736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171343</td>\n",
       "      <td>0.147917</td>\n",
       "      <td>0.252687</td>\n",
       "      <td>-0.094151</td>\n",
       "      <td>0.364434</td>\n",
       "      <td>-0.205335</td>\n",
       "      <td>0.350207</td>\n",
       "      <td>-0.043956</td>\n",
       "      <td>0.015755</td>\n",
       "      <td>128.829671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568618</th>\n",
       "      <td>0.244960</td>\n",
       "      <td>4.234850</td>\n",
       "      <td>-6.855685</td>\n",
       "      <td>7.329051</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>-2.714794</td>\n",
       "      <td>-1.699624</td>\n",
       "      <td>0.648371</td>\n",
       "      <td>-3.340750</td>\n",
       "      <td>-4.625396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524483</td>\n",
       "      <td>0.383964</td>\n",
       "      <td>-0.303575</td>\n",
       "      <td>0.071619</td>\n",
       "      <td>-0.397579</td>\n",
       "      <td>-0.625759</td>\n",
       "      <td>0.466486</td>\n",
       "      <td>0.585703</td>\n",
       "      <td>0.229681</td>\n",
       "      <td>0.842867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568619</th>\n",
       "      <td>-17.007426</td>\n",
       "      <td>9.737082</td>\n",
       "      <td>-23.810473</td>\n",
       "      <td>11.822667</td>\n",
       "      <td>-9.886202</td>\n",
       "      <td>-2.527396</td>\n",
       "      <td>-17.351003</td>\n",
       "      <td>1.890999</td>\n",
       "      <td>-6.261504</td>\n",
       "      <td>-12.903188</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002336</td>\n",
       "      <td>-2.333251</td>\n",
       "      <td>0.967427</td>\n",
       "      <td>1.254526</td>\n",
       "      <td>-1.052073</td>\n",
       "      <td>0.050394</td>\n",
       "      <td>0.673376</td>\n",
       "      <td>2.104274</td>\n",
       "      <td>-1.421160</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568620</th>\n",
       "      <td>-7.232802</td>\n",
       "      <td>5.318540</td>\n",
       "      <td>-9.339838</td>\n",
       "      <td>7.518170</td>\n",
       "      <td>-7.436339</td>\n",
       "      <td>-2.707816</td>\n",
       "      <td>-10.832284</td>\n",
       "      <td>4.530012</td>\n",
       "      <td>-6.802004</td>\n",
       "      <td>-11.874749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566636</td>\n",
       "      <td>2.260735</td>\n",
       "      <td>0.332892</td>\n",
       "      <td>0.141710</td>\n",
       "      <td>0.552338</td>\n",
       "      <td>0.648835</td>\n",
       "      <td>0.234799</td>\n",
       "      <td>1.331492</td>\n",
       "      <td>0.097281</td>\n",
       "      <td>85.227524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568621</th>\n",
       "      <td>1.882212</td>\n",
       "      <td>1.237328</td>\n",
       "      <td>-2.104280</td>\n",
       "      <td>4.212212</td>\n",
       "      <td>1.236413</td>\n",
       "      <td>-0.558348</td>\n",
       "      <td>0.437785</td>\n",
       "      <td>-0.084843</td>\n",
       "      <td>-1.226868</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200744</td>\n",
       "      <td>-0.027699</td>\n",
       "      <td>0.021985</td>\n",
       "      <td>0.015450</td>\n",
       "      <td>-0.040732</td>\n",
       "      <td>0.162731</td>\n",
       "      <td>0.096060</td>\n",
       "      <td>-0.006269</td>\n",
       "      <td>0.015953</td>\n",
       "      <td>5.717281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568622</th>\n",
       "      <td>-1.203842</td>\n",
       "      <td>1.789733</td>\n",
       "      <td>-2.422909</td>\n",
       "      <td>5.196282</td>\n",
       "      <td>-0.536742</td>\n",
       "      <td>1.195890</td>\n",
       "      <td>0.529167</td>\n",
       "      <td>-0.020806</td>\n",
       "      <td>-2.213465</td>\n",
       "      <td>-0.790285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143092</td>\n",
       "      <td>-0.279794</td>\n",
       "      <td>-0.588226</td>\n",
       "      <td>0.480964</td>\n",
       "      <td>-0.038036</td>\n",
       "      <td>-0.485578</td>\n",
       "      <td>0.096606</td>\n",
       "      <td>-0.174802</td>\n",
       "      <td>-0.675285</td>\n",
       "      <td>323.936203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568623</th>\n",
       "      <td>0.397940</td>\n",
       "      <td>2.548509</td>\n",
       "      <td>-5.757351</td>\n",
       "      <td>4.480716</td>\n",
       "      <td>-2.395831</td>\n",
       "      <td>-2.219790</td>\n",
       "      <td>-4.704193</td>\n",
       "      <td>1.232102</td>\n",
       "      <td>-0.709526</td>\n",
       "      <td>-5.440958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554489</td>\n",
       "      <td>0.751309</td>\n",
       "      <td>0.111817</td>\n",
       "      <td>0.670040</td>\n",
       "      <td>0.113418</td>\n",
       "      <td>-1.909267</td>\n",
       "      <td>0.330108</td>\n",
       "      <td>0.700990</td>\n",
       "      <td>0.178995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568624</th>\n",
       "      <td>-2.095753</td>\n",
       "      <td>3.591669</td>\n",
       "      <td>-4.461400</td>\n",
       "      <td>2.683254</td>\n",
       "      <td>-2.031607</td>\n",
       "      <td>-2.282432</td>\n",
       "      <td>-4.143670</td>\n",
       "      <td>1.679685</td>\n",
       "      <td>-1.292826</td>\n",
       "      <td>-6.655523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477321</td>\n",
       "      <td>0.626882</td>\n",
       "      <td>-0.509030</td>\n",
       "      <td>-0.010177</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.096023</td>\n",
       "      <td>0.310210</td>\n",
       "      <td>0.515966</td>\n",
       "      <td>0.277868</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568625</th>\n",
       "      <td>-0.421469</td>\n",
       "      <td>0.571437</td>\n",
       "      <td>-1.818966</td>\n",
       "      <td>0.802900</td>\n",
       "      <td>-1.965279</td>\n",
       "      <td>-0.963056</td>\n",
       "      <td>-3.045503</td>\n",
       "      <td>0.630382</td>\n",
       "      <td>-0.648149</td>\n",
       "      <td>-1.890273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565743</td>\n",
       "      <td>0.649599</td>\n",
       "      <td>0.863705</td>\n",
       "      <td>0.205032</td>\n",
       "      <td>-0.008525</td>\n",
       "      <td>-1.110776</td>\n",
       "      <td>-0.422440</td>\n",
       "      <td>0.468151</td>\n",
       "      <td>0.064867</td>\n",
       "      <td>27.000915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568626</th>\n",
       "      <td>1.909226</td>\n",
       "      <td>1.033124</td>\n",
       "      <td>-2.118774</td>\n",
       "      <td>3.920691</td>\n",
       "      <td>1.600209</td>\n",
       "      <td>0.417248</td>\n",
       "      <td>0.337490</td>\n",
       "      <td>0.048679</td>\n",
       "      <td>-1.221553</td>\n",
       "      <td>0.480388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139854</td>\n",
       "      <td>-0.021100</td>\n",
       "      <td>0.109520</td>\n",
       "      <td>-0.078179</td>\n",
       "      <td>-0.350561</td>\n",
       "      <td>0.327578</td>\n",
       "      <td>0.147477</td>\n",
       "      <td>-0.010350</td>\n",
       "      <td>-0.008338</td>\n",
       "      <td>8.743034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568627</th>\n",
       "      <td>-14.571709</td>\n",
       "      <td>7.746710</td>\n",
       "      <td>-21.741075</td>\n",
       "      <td>11.912345</td>\n",
       "      <td>-8.242777</td>\n",
       "      <td>-2.246413</td>\n",
       "      <td>-15.732113</td>\n",
       "      <td>-0.044098</td>\n",
       "      <td>-6.363434</td>\n",
       "      <td>-13.286072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>-2.363264</td>\n",
       "      <td>1.108336</td>\n",
       "      <td>1.025104</td>\n",
       "      <td>-1.035528</td>\n",
       "      <td>-0.275003</td>\n",
       "      <td>0.640166</td>\n",
       "      <td>2.163762</td>\n",
       "      <td>-1.399429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568628</th>\n",
       "      <td>-1.820925</td>\n",
       "      <td>1.173996</td>\n",
       "      <td>-1.103456</td>\n",
       "      <td>2.123826</td>\n",
       "      <td>-2.316609</td>\n",
       "      <td>-0.772265</td>\n",
       "      <td>-2.219312</td>\n",
       "      <td>0.683810</td>\n",
       "      <td>-1.098120</td>\n",
       "      <td>-2.642369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057264</td>\n",
       "      <td>0.623544</td>\n",
       "      <td>0.713159</td>\n",
       "      <td>0.308512</td>\n",
       "      <td>0.253750</td>\n",
       "      <td>-0.258768</td>\n",
       "      <td>0.860802</td>\n",
       "      <td>0.149308</td>\n",
       "      <td>0.222118</td>\n",
       "      <td>110.751723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568629</th>\n",
       "      <td>-2.496560</td>\n",
       "      <td>0.459037</td>\n",
       "      <td>-1.958570</td>\n",
       "      <td>3.244971</td>\n",
       "      <td>-3.103204</td>\n",
       "      <td>0.668415</td>\n",
       "      <td>-1.427989</td>\n",
       "      <td>0.959702</td>\n",
       "      <td>-1.855220</td>\n",
       "      <td>-3.825791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828523</td>\n",
       "      <td>0.757568</td>\n",
       "      <td>0.671647</td>\n",
       "      <td>0.978078</td>\n",
       "      <td>-0.195034</td>\n",
       "      <td>0.035564</td>\n",
       "      <td>0.644903</td>\n",
       "      <td>0.529199</td>\n",
       "      <td>-0.036791</td>\n",
       "      <td>478.805216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568630 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2         V3         V4         V5        V6  \\\n",
       "0       -1.359807  -0.072781   2.536347   1.378155  -0.338321  0.462388   \n",
       "1        1.191857   0.266151   0.166480   0.448154   0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163   1.773209   0.379780  -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226   1.792993  -0.863291  -0.010309  1.247203   \n",
       "4       -1.158233   0.877737   1.548718   0.403034  -0.407193  0.095921   \n",
       "5       -0.425966   0.960523   1.141109  -0.168252   0.420987 -0.029728   \n",
       "6        1.229658   0.141004   0.045371   1.202613   0.191881  0.272708   \n",
       "7       -0.644269   1.417964   1.074380  -0.492199   0.948934  0.428118   \n",
       "8       -0.894286   0.286157  -0.113192  -0.271526   2.669599  3.721818   \n",
       "9       -0.338262   1.119593   1.044367  -0.222187   0.499361 -0.246761   \n",
       "10       1.449044  -1.176339   0.913860  -1.375667  -1.971383 -0.629152   \n",
       "11       0.384978   0.616109  -0.874300  -0.094019   2.924584  3.317027   \n",
       "12       1.249999  -1.221637   0.383930  -1.234899  -1.485419 -0.753230   \n",
       "13       1.069374   0.287722   0.828613   2.712520  -0.178398  0.337544   \n",
       "14      -2.791855  -0.327771   1.641750   1.767473  -0.136588  0.807596   \n",
       "15      -0.752417   0.345485   2.057323  -1.468643  -1.158394 -0.077850   \n",
       "16       1.103215  -0.040296   1.267332   1.289091  -0.735997  0.288069   \n",
       "17      -0.436905   0.918966   0.924591  -0.727219   0.915679 -0.127867   \n",
       "18      -5.401258  -5.450148   1.186305   1.736239   3.049106 -1.763406   \n",
       "19       1.492936  -1.029346   0.454795  -1.438026  -1.555434 -0.720961   \n",
       "20       0.694885  -1.361819   1.029221   0.834159  -1.191209  1.309109   \n",
       "21       0.962496   0.328461  -0.171479   2.109204   1.129566  1.696038   \n",
       "22       1.166616   0.502120  -0.067300   2.261569   0.428804  0.089474   \n",
       "23       0.247491   0.277666   1.185471  -0.092603  -1.314394 -0.150116   \n",
       "24      -1.946525  -0.044901  -0.405570  -1.013057   2.941968  2.955053   \n",
       "25      -2.074295  -0.121482   1.322021   0.410008   0.295198 -0.959537   \n",
       "26       1.173285   0.353498   0.283905   1.133563  -0.172577 -0.916054   \n",
       "27       1.322707  -0.174041   0.434555   0.576038  -0.836758 -0.831083   \n",
       "28      -0.414289   0.905437   1.727453   1.473471   0.007443 -0.200331   \n",
       "29       1.059387  -0.175319   1.266130   1.186110  -0.786002  0.578435   \n",
       "...           ...        ...        ...        ...        ...       ...   \n",
       "568600  -0.431850   1.740233  -1.287095   3.812569  -1.319112 -0.555231   \n",
       "568601   1.141351   2.261760  -4.341890   5.415610   0.478417 -1.125233   \n",
       "568602  -5.416994   5.170464  -7.532386   7.952700  -2.700946 -1.626737   \n",
       "568603  -1.626548   1.004557  -1.560578   2.785502  -2.510142 -0.361643   \n",
       "568604  -0.565370   1.312136  -3.436349   1.866344  -0.256212 -2.177116   \n",
       "568605  -7.446569  -7.323783  -4.002447   3.645846   5.737345 -6.054929   \n",
       "568606  -3.159428   3.079884  -5.377163   5.722466  -2.313808 -1.643678   \n",
       "568607  -1.450912   2.135279  -1.279962   1.232791  -0.433712 -1.356919   \n",
       "568608   1.209434   2.577845  -5.370135   5.331441   1.262602 -1.342694   \n",
       "568609  -1.438377  -3.069143  -6.433362   3.423775  -1.300889 -1.509051   \n",
       "568610  -0.956192   1.975265  -1.937979   2.098744  -1.108404 -1.237650   \n",
       "568611  -3.189151   2.365126  -4.019560   0.494608  -2.187439 -1.725685   \n",
       "568612 -27.974616  15.650318 -29.025672   6.423893 -20.428470 -4.835199   \n",
       "568613  -1.255264   2.465390  -2.875635   2.367229  -1.366626 -0.947491   \n",
       "568614  -1.091079  -0.973877  -0.733176   0.621101   7.879658 -4.031369   \n",
       "568615   1.224977   2.560976  -5.028949   5.369525   1.097473 -1.335297   \n",
       "568616  -1.006315   1.306498  -0.478097   2.179963  -1.087580 -0.118490   \n",
       "568617  -0.691588   0.618486   1.019345  -0.217790  -0.564045 -0.609945   \n",
       "568618   0.244960   4.234850  -6.855685   7.329051   0.705109 -2.714794   \n",
       "568619 -17.007426   9.737082 -23.810473  11.822667  -9.886202 -2.527396   \n",
       "568620  -7.232802   5.318540  -9.339838   7.518170  -7.436339 -2.707816   \n",
       "568621   1.882212   1.237328  -2.104280   4.212212   1.236413 -0.558348   \n",
       "568622  -1.203842   1.789733  -2.422909   5.196282  -0.536742  1.195890   \n",
       "568623   0.397940   2.548509  -5.757351   4.480716  -2.395831 -2.219790   \n",
       "568624  -2.095753   3.591669  -4.461400   2.683254  -2.031607 -2.282432   \n",
       "568625  -0.421469   0.571437  -1.818966   0.802900  -1.965279 -0.963056   \n",
       "568626   1.909226   1.033124  -2.118774   3.920691   1.600209  0.417248   \n",
       "568627 -14.571709   7.746710 -21.741075  11.912345  -8.242777 -2.246413   \n",
       "568628  -1.820925   1.173996  -1.103456   2.123826  -2.316609 -0.772265   \n",
       "568629  -2.496560   0.459037  -1.958570   3.244971  -3.103204  0.668415   \n",
       "\n",
       "               V7         V8        V9        V10     ...            V20  \\\n",
       "0        0.239599   0.098698  0.363787   0.090794     ...       0.251412   \n",
       "1       -0.078803   0.085102 -0.255425  -0.166974     ...      -0.069083   \n",
       "2        0.791461   0.247676 -1.514654   0.207643     ...       0.524980   \n",
       "3        0.237609   0.377436 -1.387024  -0.054952     ...      -0.208038   \n",
       "4        0.592941  -0.270533  0.817739   0.753074     ...       0.408542   \n",
       "5        0.476201   0.260314 -0.568671  -0.371407     ...       0.084968   \n",
       "6       -0.005159   0.081213  0.464960  -0.099254     ...      -0.219633   \n",
       "7        1.120631  -3.807864  0.615375   1.249376     ...      -0.156742   \n",
       "8        0.370145   0.851084 -0.392048  -0.410430     ...       0.052736   \n",
       "9        0.651583   0.069539 -0.736727  -0.366846     ...       0.203711   \n",
       "10      -1.423236   0.048456 -1.720408   1.626659     ...      -0.387226   \n",
       "11       0.470455   0.538247 -0.558895   0.309755     ...       0.125992   \n",
       "12      -0.689405  -0.227487 -2.094011   1.323729     ...      -0.102756   \n",
       "13      -0.096717   0.115982 -0.221083   0.460230     ...      -0.153197   \n",
       "14      -0.422911  -1.907107  0.755713   1.151087     ...      -1.582122   \n",
       "15      -0.608581   0.003603 -0.436167   0.747731     ...       0.263451   \n",
       "16      -0.586057   0.189380  0.782333  -0.267975     ...      -0.113910   \n",
       "17       0.707642   0.087962 -0.665271  -0.737980     ...      -0.047021   \n",
       "18      -1.559738   0.160842  1.233090   0.345173     ...      -2.196848   \n",
       "19      -1.080664  -0.053127 -1.978682   1.638076     ...      -0.387910   \n",
       "20      -0.878586   0.445290 -0.446196   0.568521     ...      -0.138334   \n",
       "21       0.107712   0.521502 -1.191311   0.724396     ...      -0.269321   \n",
       "22       0.241147   0.138082 -0.989162   0.922175     ...      -0.307169   \n",
       "23      -0.946365  -1.617935  1.544071  -0.829881     ...      -0.230983   \n",
       "24      -0.063063   0.855546  0.049967   0.573743     ...      -0.216715   \n",
       "25       0.543985  -0.104627  0.475664   0.149451     ...      -0.386694   \n",
       "26       0.369025  -0.327260 -0.246651  -0.046139     ...       0.027878   \n",
       "27      -0.264905  -0.220982 -1.071425   0.868559     ...      -0.522951   \n",
       "28       0.740228  -0.029247 -0.593392  -0.346188     ...       0.097308   \n",
       "29      -0.767084   0.401046  0.699500  -0.064738     ...      -0.178023   \n",
       "...           ...        ...       ...        ...     ...            ...   \n",
       "568600  -2.741254  -0.179773 -1.506202  -3.142770     ...       0.457270   \n",
       "568601  -1.557897   0.450030 -2.287252  -2.878547     ...       0.191662   \n",
       "568602  -6.248474   2.907716 -4.414663  -7.324847     ...       0.261370   \n",
       "568603  -1.530560   0.761608 -1.435956  -3.954546     ...       1.113034   \n",
       "568604  -1.987386   0.525516 -0.687097  -4.050907     ...       0.404327   \n",
       "568605  -6.029529   1.537511 -0.633829  -4.021872     ...       2.917522   \n",
       "568606  -4.889622   1.027144 -2.361972  -5.323902     ...       0.316850   \n",
       "568607  -1.563957  -0.463728 -1.293990  -3.078211     ...       0.269548   \n",
       "568608  -1.068535   0.303722 -2.693402  -3.059046     ...       0.215596   \n",
       "568609   0.592870  -0.255988 -1.139386  -4.148398     ...       3.072016   \n",
       "568610  -2.191654   0.881855 -1.780943  -3.396356     ...       0.242237   \n",
       "568611  -3.150328  -0.977580 -0.003257  -5.104877     ...      -0.054859   \n",
       "568612 -19.265164  18.407850 -3.663920  -7.996159     ...       1.699545   \n",
       "568613  -3.063485   1.164484 -2.283344  -4.848886     ...       0.558561   \n",
       "568614  -6.123988  -0.637401  1.559775   1.237269     ...      -1.307216   \n",
       "568615  -1.129983   0.224403 -2.566532  -3.083057     ...       0.275249   \n",
       "568616  -2.105637   0.641459 -1.266116  -3.216521     ...       0.533261   \n",
       "568617   0.614703   0.090635 -0.152099  -1.113736     ...      -0.171343   \n",
       "568618  -1.699624   0.648371 -3.340750  -4.625396     ...       0.524483   \n",
       "568619 -17.351003   1.890999 -6.261504 -12.903188     ...       1.002336   \n",
       "568620 -10.832284   4.530012 -6.802004 -11.874749     ...       0.566636   \n",
       "568621   0.437785  -0.084843 -1.226868   0.183469     ...      -0.200744   \n",
       "568622   0.529167  -0.020806 -2.213465  -0.790285     ...      -0.143092   \n",
       "568623  -4.704193   1.232102 -0.709526  -5.440958     ...       0.554489   \n",
       "568624  -4.143670   1.679685 -1.292826  -6.655523     ...       0.477321   \n",
       "568625  -3.045503   0.630382 -0.648149  -1.890273     ...       0.565743   \n",
       "568626   0.337490   0.048679 -1.221553   0.480388     ...      -0.139854   \n",
       "568627 -15.732113  -0.044098 -6.363434 -13.286072     ...       0.999298   \n",
       "568628  -2.219312   0.683810 -1.098120  -2.642369     ...       0.057264   \n",
       "568629  -1.427989   0.959702 -1.855220  -3.825791     ...       0.828523   \n",
       "\n",
       "             V21       V22        V23       V24       V25       V26       V27  \\\n",
       "0      -0.018307  0.277838  -0.110474  0.066928  0.128539 -0.189115  0.133558   \n",
       "1      -0.225775 -0.638672   0.101288 -0.339846  0.167170  0.125895 -0.008983   \n",
       "2       0.247998  0.771679   0.909412 -0.689281 -0.327642 -0.139097 -0.055353   \n",
       "3      -0.108300  0.005274  -0.190321 -1.175575  0.647376 -0.221929  0.062723   \n",
       "4      -0.009431  0.798278  -0.137458  0.141267 -0.206010  0.502292  0.219422   \n",
       "5      -0.208254 -0.559825  -0.026398 -0.371427 -0.232794  0.105915  0.253844   \n",
       "6      -0.167716 -0.270710  -0.154104 -0.780055  0.750137 -0.257237  0.034507   \n",
       "7       1.943465 -1.015455   0.057504 -0.649709 -0.415267 -0.051634 -1.206921   \n",
       "8      -0.073425 -0.268092  -0.204233  1.011592  0.373205 -0.384157  0.011747   \n",
       "9      -0.246914 -0.633753  -0.120794 -0.385050 -0.069733  0.094199  0.246219   \n",
       "10     -0.009302  0.313894   0.027740  0.500512  0.251367 -0.129478  0.042850   \n",
       "11      0.049924  0.238422   0.009130  0.996710 -0.767315 -0.492208  0.042472   \n",
       "12     -0.231809 -0.483285   0.084668  0.392831  0.161135 -0.354990  0.026416   \n",
       "13     -0.036876  0.074412  -0.071407  0.104744  0.548265  0.104094  0.021491   \n",
       "14      1.151663  0.222182   1.020586  0.028317 -0.232746 -0.235557 -0.164778   \n",
       "15      0.499625  1.353650  -0.256573 -0.065084 -0.039124 -0.087086 -0.180998   \n",
       "16     -0.024612  0.196002   0.013802  0.103758  0.364298 -0.382261  0.092809   \n",
       "17     -0.194796 -0.672638  -0.156858 -0.888386 -0.342413 -0.049027  0.079692   \n",
       "18     -0.503600  0.984460   2.458589  0.042119 -0.481631 -0.621272  0.392053   \n",
       "19     -0.177650 -0.175074   0.040002  0.295814  0.332931 -0.220385  0.022298   \n",
       "20     -0.295583 -0.571955  -0.050881 -0.304215  0.072001 -0.422234  0.086553   \n",
       "21      0.143997  0.402492  -0.048508 -1.371866  0.390814  0.199964  0.016371   \n",
       "22      0.018702 -0.061972  -0.103855 -0.370415  0.603200  0.108556 -0.040521   \n",
       "23      1.650180  0.200454  -0.185353  0.423073  0.820591 -0.227632  0.336634   \n",
       "24     -0.579526 -0.799229   0.870300  0.983421  0.321201  0.149650  0.707519   \n",
       "25     -0.403639 -0.227404   0.742435  0.398535  0.249212  0.274404  0.359969   \n",
       "26      0.067003  0.227812  -0.150487  0.435045  0.724825 -0.337082  0.016368   \n",
       "27     -0.284376 -0.323357  -0.037710  0.347151  0.559639 -0.280158  0.042335   \n",
       "28      0.077237  0.457331  -0.038500  0.642522 -0.183891 -0.277464  0.182687   \n",
       "29      0.013676  0.213734   0.014462  0.002951  0.294638 -0.395070  0.081461   \n",
       "...          ...       ...        ...       ...       ...       ...       ...   \n",
       "568600  0.304943  0.196853  -0.188819  0.337820  0.576921  0.077519  0.560569   \n",
       "568601  0.216656 -0.410046  -0.047798 -0.634643  0.256817  0.094138  0.492474   \n",
       "568602  1.247857  0.463935  -0.111089 -0.511251 -0.144428  0.438673 -0.089150   \n",
       "568603  0.739270  0.447762   0.534878  0.318922  0.034624  0.792849  0.449038   \n",
       "568604  0.714316  0.693659  -0.220986 -0.006995  0.386094  0.074312  0.452447   \n",
       "568605  1.189353 -0.893352  -0.292237 -0.488294  0.162431  0.411722  0.735777   \n",
       "568606  0.870687  0.188216   0.235149 -0.229123  0.028015  0.089998 -0.234685   \n",
       "568607  1.119449 -0.018298  -0.214961  0.148974  0.017302 -0.476409  0.479423   \n",
       "568608  0.242171 -0.429575  -0.115692  0.083117  0.523828  0.177272  0.457655   \n",
       "568609  1.277075 -0.524807  -1.475724 -0.448835  0.119610  0.110438  0.177885   \n",
       "568610  0.562334  0.126448  -0.054446 -0.038993  0.114418 -0.125625  0.428352   \n",
       "568611  1.825581 -0.343719  -0.155675  0.047872  0.022436 -0.757765 -0.899771   \n",
       "568612  1.802826 -2.073489  -1.278746  0.166239  2.009259 -0.210954  1.320494   \n",
       "568613  0.657560  0.092177  -0.218306 -0.512257  0.220224  0.755082  0.629784   \n",
       "568614  1.236501 -0.066220 -10.324416 -0.304119 -2.604644 -0.455704  0.564041   \n",
       "568615  0.229618 -0.361572  -0.120752 -0.109754  0.520538  0.172888  0.476522   \n",
       "568616  0.461527  0.418300  -0.123274  0.165642 -0.016674 -0.079035  0.466865   \n",
       "568617  0.147917  0.252687  -0.094151  0.364434 -0.205335  0.350207 -0.043956   \n",
       "568618  0.383964 -0.303575   0.071619 -0.397579 -0.625759  0.466486  0.585703   \n",
       "568619 -2.333251  0.967427   1.254526 -1.052073  0.050394  0.673376  2.104274   \n",
       "568620  2.260735  0.332892   0.141710  0.552338  0.648835  0.234799  1.331492   \n",
       "568621 -0.027699  0.021985   0.015450 -0.040732  0.162731  0.096060 -0.006269   \n",
       "568622 -0.279794 -0.588226   0.480964 -0.038036 -0.485578  0.096606 -0.174802   \n",
       "568623  0.751309  0.111817   0.670040  0.113418 -1.909267  0.330108  0.700990   \n",
       "568624  0.626882 -0.509030  -0.010177  0.008584  0.096023  0.310210  0.515966   \n",
       "568625  0.649599  0.863705   0.205032 -0.008525 -1.110776 -0.422440  0.468151   \n",
       "568626 -0.021100  0.109520  -0.078179 -0.350561  0.327578  0.147477 -0.010350   \n",
       "568627 -2.363264  1.108336   1.025104 -1.035528 -0.275003  0.640166  2.163762   \n",
       "568628  0.623544  0.713159   0.308512  0.253750 -0.258768  0.860802  0.149308   \n",
       "568629  0.757568  0.671647   0.978078 -0.195034  0.035564  0.644903  0.529199   \n",
       "\n",
       "             V28       Amount  \n",
       "0      -0.021053   149.620000  \n",
       "1       0.014724     2.690000  \n",
       "2      -0.059752   378.660000  \n",
       "3       0.061458   123.500000  \n",
       "4       0.215153    69.990000  \n",
       "5       0.081080     3.670000  \n",
       "6       0.005168     4.990000  \n",
       "7      -1.085339    40.800000  \n",
       "8       0.142404    93.200000  \n",
       "9       0.083076     3.680000  \n",
       "10      0.016253     7.800000  \n",
       "11     -0.054337     9.990000  \n",
       "12      0.042422   121.500000  \n",
       "13      0.021293    27.500000  \n",
       "14     -0.030154    58.800000  \n",
       "15      0.129394    15.990000  \n",
       "16      0.037051    12.990000  \n",
       "17      0.131024     0.890000  \n",
       "18      0.949594    46.800000  \n",
       "19      0.007602     5.000000  \n",
       "20      0.063499   231.710000  \n",
       "21     -0.014605    34.090000  \n",
       "22     -0.011418     2.280000  \n",
       "23      0.250475    22.750000  \n",
       "24      0.014600     0.890000  \n",
       "25      0.243232    26.430000  \n",
       "26      0.030041    41.880000  \n",
       "27      0.028822    16.000000  \n",
       "28      0.152665    33.000000  \n",
       "29      0.024220    12.990000  \n",
       "...          ...          ...  \n",
       "568600  0.231904     3.386876  \n",
       "568601  0.263350     2.743238  \n",
       "568602 -0.463596     0.059928  \n",
       "568603  0.257831   317.952570  \n",
       "568604  0.093326    22.499206  \n",
       "568605 -1.183909    30.754884  \n",
       "568606  0.699816    25.778693  \n",
       "568607 -0.015868     0.974453  \n",
       "568608  0.272989     3.628299  \n",
       "568609  0.458281  1433.966226  \n",
       "568610  0.247689     0.945247  \n",
       "568611 -0.839433    86.502020  \n",
       "568612  0.386623    99.990000  \n",
       "568613  0.247485     0.018043  \n",
       "568614  0.287454     0.839537  \n",
       "568615  0.275160     1.440027  \n",
       "568616  0.096961    39.532234  \n",
       "568617  0.015755   128.829671  \n",
       "568618  0.229681     0.842867  \n",
       "568619 -1.421160     1.000000  \n",
       "568620  0.097281    85.227524  \n",
       "568621  0.015953     5.717281  \n",
       "568622 -0.675285   323.936203  \n",
       "568623  0.178995     1.000000  \n",
       "568624  0.277868     1.000000  \n",
       "568625  0.064867    27.000915  \n",
       "568626 -0.008338     8.743034  \n",
       "568627 -1.399429     1.000000  \n",
       "568628  0.222118   110.751723  \n",
       "568629 -0.036791   478.805216  \n",
       "\n",
       "[568630 rows x 29 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os_data_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLITTING THE DATASET INTO TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over = os_data_X[['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19',\n",
    "               'V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount']]\n",
    "y_over = os_data_y['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_over_train, X_over_test, y_over_train, y_over_test = train_test_split(X_over,y_over,test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE ON LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-5701b827ff56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_over_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_over_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of Features: %d\"\u001b[0m\u001b[1;33m%\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Selected features: %s\"\u001b[0m\u001b[1;33m%\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \"\"\"\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    171\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;31m# Get coefs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1233\u001b[1;33m                 sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1234\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         epsilon, sample_weight)\n\u001b[0m\u001b[0;32m    891\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model)\n",
    "fit = rfe.fit(X_over_train,y_over_train)\n",
    "print(\"Number of Features: %d\"% fit.n_features_)\n",
    "print(\"Selected features: %s\"% fit.support_)\n",
    "print(\"Ranking of features: %s\"% fit.ranking_)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_over_train[['V4','V8','V9','V10','V13','V14','V16','V20','V21','V22','V24','V25','V26','V27']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[194683   4460]\n",
      " [ 15578 183320]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95    199143\n",
      "          1       0.98      0.92      0.95    198898\n",
      "\n",
      "avg / total       0.95      0.95      0.95    398041\n",
      "\n",
      "0.9496584522699922\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X, y_over_train)\n",
    "\n",
    "y_pred = classifier.predict(X)\n",
    "print(confusion_matrix(y_over_train,y_pred))  \n",
    "print(classification_report(y_over_train,y_pred)) \n",
    "print(accuracy_score(y_over_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83628  1544]\n",
      " [ 5536 79881]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96     85172\n",
      "          1       0.98      0.94      0.96     85417\n",
      "\n",
      "avg / total       0.96      0.96      0.96    170589\n",
      "\n",
      "0.9584967377732445\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_over_test, y_over_test)\n",
    "y_pred = classifier.predict(X_over_test)\n",
    "print(confusion_matrix(y_over_test,y_pred))  \n",
    "print(classification_report(y_over_test,y_pred)) \n",
    "print(accuracy_score(y_over_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__C': 10.01}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9496710137900367"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logregpipe = Pipeline([('scale', StandardScaler()),\n",
    "                   ('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "\n",
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'logreg__C':np.arange(0.01,100,10)}\n",
    "logreg_cv = GridSearchCV(logregpipe,param_grid,cv=5,return_train_score=True)\n",
    "logreg_cv.fit(X,y_over_train)\n",
    "print(logreg_cv.best_params_)\n",
    "\n",
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X,y_over_train)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X,y_over_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9585319100293689"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X_over_test,y_over_test)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X_over_test,y_over_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9496835753100811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predicted = cross_validation.cross_val_predict(LogisticRegression(), X, y_over_train, cv=10)\n",
    "print (metrics.accuracy_score(y_over_train, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96     85172\n",
      "          1       0.98      0.94      0.96     85417\n",
      "\n",
      "avg / total       0.96      0.96      0.96    170589\n",
      "\n",
      "0.9584322553036831\n"
     ]
    }
   ],
   "source": [
    "predicted1 = cross_validation.cross_val_predict(LogisticRegression(), X_over_test, y_over_test, cv=10)\n",
    "\n",
    "print (metrics.classification_report(y_over_test, predicted1))\n",
    "print (metrics.accuracy_score(y_over_test, predicted1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K BEST ON LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores_: [8.90094295e+04 1.34490388e+05 1.88238248e+05 4.20919510e+05\n",
      " 7.01624088e+04 8.27595776e+04 1.17168375e+05 2.23421604e+03\n",
      " 2.02211994e+05 2.80165278e+05 3.89901322e+05 3.69625988e+05\n",
      " 1.92694387e+03 5.77083297e+05 5.09794479e+02 2.29924455e+05\n",
      " 1.94388512e+05 1.19822984e+05 3.01968294e+04 1.46847404e+04\n",
      " 7.76561530e+03 1.42699446e+01 6.32743066e+01 4.76825994e+03\n",
      " 1.19644623e+03 1.45353018e+03 4.46225074e+03 4.20967142e+03\n",
      " 1.73454612e+03]\n",
      "pvalues_: [0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 8.28014570e-113 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 1.58396646e-004 1.80301758e-015 0.00000000e+000\n",
      " 8.87098339e-262 1.84523094e-317 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000]\n",
      "selected index: [ 1  2  3  8  9 10 11 13 15 16]\n",
      "after transform: [[  1.2146421   -0.8679004   -0.53464298 ...  -0.68662824   0.52257795\n",
      "    0.46459217]\n",
      " [  3.36853414  -2.01061842   4.22830633 ...  -6.79763031  -2.41810787\n",
      "   -3.57575034]\n",
      " [  0.80734572   0.33517905  -0.2461202  ...   0.60329476  -0.32094859\n",
      "   -0.48751702]\n",
      " ...\n",
      " [  0.74782839   1.78478144   0.899612   ...  -0.04321571   0.22720288\n",
      "   -0.55825561]\n",
      " [  5.32843806  -7.38995682   6.52185477 ... -11.07530394  -2.46408239\n",
      "   -2.89973746]\n",
      " [  3.8842593   -6.50167547   2.31966299 ...  -8.49482648  -4.19108931\n",
      "   -7.6011712 ]]\n"
     ]
    }
   ],
   "source": [
    "#array = under_sample.values\n",
    "test = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = test.fit(X_over_train, y_over_train)\n",
    "print(\"scores_:\",test.scores_)\n",
    "print(\"pvalues_:\",test.pvalues_)\n",
    "print(\"selected index:\",test.get_support(True))\n",
    "print(\"after transform:\",test.transform(X_over_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "## fitiing the model\n",
    "X = X_over_train[['V3','V4','V7','V9','V10','V11','V12','V14','V16','V17']]\n",
    "logreg.fit(X, y_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[195726   3417]\n",
      " [ 12514 186384]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96    199143\n",
      "          1       0.98      0.94      0.96    198898\n",
      "\n",
      "avg / total       0.96      0.96      0.96    398041\n",
      "\n",
      "0.9599764848344768\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_over_train, y_over_train)\n",
    "y_pred = classifier.predict(X_over_train)\n",
    "print(confusion_matrix(y_over_train,y_pred))  \n",
    "print(classification_report(y_over_train,y_pred)) \n",
    "print(accuracy_score(y_over_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fitiing the model\n",
    "X2 = X_over_test[['V2','V3','V4','V9','V10','V11','V12','V14','V16','V17']]\n",
    "# logreg.fit(X2, y_under_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83454  1718]\n",
      " [ 6623 78794]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95     85172\n",
      "          1       0.98      0.92      0.95     85417\n",
      "\n",
      "avg / total       0.95      0.95      0.95    170589\n",
      "\n",
      "0.9511047019444395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X2, y_over_test)\n",
    "y_pred = classifier.predict(X2)\n",
    "print(confusion_matrix(y_over_test,y_pred))  \n",
    "print(classification_report(y_over_test,y_pred)) \n",
    "print(accuracy_score(y_over_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__C': 30.01}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9544469037109242"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logregpipe = Pipeline([('scale', StandardScaler()),\n",
    "                   ('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "\n",
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'logreg__C':np.arange(0.01,100,10)}\n",
    "logreg_cv = GridSearchCV(logregpipe,param_grid,cv=5,return_train_score=True)\n",
    "logreg_cv.fit(X,y_over_train)\n",
    "print(logreg_cv.best_params_)\n",
    "\n",
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X,y_over_train)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X,y_over_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9511047019444395"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X2,y_over_test)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X2,y_over_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9544418791029065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predicted = cross_validation.cross_val_predict(LogisticRegression(), X, y_over_train, cv=10)\n",
    "print (metrics.accuracy_score(y_over_train, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96     85172\n",
      "          1       0.98      0.94      0.96     85417\n",
      "\n",
      "avg / total       0.96      0.96      0.96    170589\n",
      "\n",
      "0.9584322553036831\n"
     ]
    }
   ],
   "source": [
    "predicted1 = cross_validation.cross_val_predict(LogisticRegression(), X_over_test, y_over_test, cv=10)\n",
    "\n",
    "print (metrics.classification_report(y_over_test, predicted1))\n",
    "print (metrics.accuracy_score(y_over_test, predicted1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA ON LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.93486071e-01 4.51088486e-03 5.49623610e-04 5.22069220e-04\n",
      " 2.47273720e-04]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "X_under_train = pca.fit_transform(X_under_train)\n",
    "X_under_test = pca.transform(X_under_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TRAIN & TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147   2]\n",
      " [ 16 131]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94       149\n",
      "          1       0.98      0.89      0.94       147\n",
      "\n",
      "avg / total       0.94      0.94      0.94       296\n",
      "\n",
      "0.9391891891891891\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_under_train, y_under_train)\n",
    "y_pred = classifier.predict(X_under_test)\n",
    "print(confusion_matrix(y_under_test,y_pred))  \n",
    "print(classification_report(y_under_test,y_pred)) \n",
    "print(accuracy_score(y_under_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search on test & train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__C': 60.01}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9600317555226723"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logregpipe = Pipeline([('scale', StandardScaler()),\n",
    "                   ('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "\n",
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'logreg__C':np.arange(0.01,100,10)}\n",
    "logreg_cv = GridSearchCV(logregpipe,param_grid,cv=5,return_train_score=True)\n",
    "logreg_cv.fit(X_over_train,y_over_train)\n",
    "print(logreg_cv.best_params_)\n",
    "\n",
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X_over_train,y_over_train)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X_over_train,y_over_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation on test & train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9599965832665479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predicted = cross_validation.cross_val_predict(LogisticRegression(),X_over_train,y_over_train, cv=10)\n",
    "print (metrics.accuracy_score(y_over_train, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
