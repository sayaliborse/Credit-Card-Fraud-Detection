{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READING CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNDERSAMPLING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_frauds = len(df[df['Class'] == 1])\n",
    "non_fraud_indices = df[df.Class == 0].index\n",
    "non_fraud_indices = df[df.Class == 0].index\n",
    "random_indices = np.random.choice(non_fraud_indices, no_frauds, replace=False)\n",
    "fraud_indices = df[df.Class == 1].index\n",
    "under_sample_indices = np.concatenate([fraud_indices,random_indices])\n",
    "under_sample = df.loc[under_sample_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLITTING THE DATASET INTO TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under = under_sample[['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19',\n",
    "                        'V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount']]\n",
    "y_under = under_sample['Class']\n",
    "X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(X_under,y_under,test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE ON NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 14\n",
      "Selected features: [ True False  True False  True  True  True False  True  True False  True\n",
      " False  True False  True  True  True False False False False  True  True\n",
      " False False False False False]\n",
      "Ranking of features: [ 1 13  1 16  1  1  1  9  1  1 14  1  4  1  2  1  1  1 10  7 12  5  1  1\n",
      "  6  3 11  8 15]\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "rfe = RFE(model)\n",
    "fit = rfe.fit(X_under_train,y_under_train)\n",
    "print(\"Number of Features: %d\"% fit.n_features_)\n",
    "print(\"Selected features: %s\"% fit.support_)\n",
    "print(\"Ranking of features: %s\"% fit.ranking_)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[335   8]\n",
      " [ 49 296]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.98      0.92       343\n",
      "          1       0.97      0.86      0.91       345\n",
      "\n",
      "avg / total       0.92      0.92      0.92       688\n",
      "\n",
      "0.9171511627906976\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "X = X_under_train[['V1','V3','V5', 'V6', 'V7','V9','V10','V12','V14','V15','V16','V17','V18','V23','V24']]\n",
    "gnb.fit(X,y_under_train)\n",
    "y_pred = gnb.predict(X)\n",
    "print(confusion_matrix(y_under_train,y_pred))  \n",
    "print(classification_report(y_under_train,y_pred))\n",
    "print(accuracy_score(y_under_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149   0]\n",
      " [ 22 125]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       149\n",
      "          1       1.00      0.85      0.92       147\n",
      "\n",
      "avg / total       0.94      0.93      0.93       296\n",
      "\n",
      "0.9256756756756757\n"
     ]
    }
   ],
   "source": [
    "X2 = X_under_test[['V1','V3','V5', 'V6', 'V7','V9','V10','V12','V14','V15','V16','V17','V18','V23','V24']]\n",
    "y_pred = gnb.predict(X2)\n",
    "print(confusion_matrix(y_under_test,y_pred))  \n",
    "print(classification_report(y_under_test,y_pred))\n",
    "print(accuracy_score(y_under_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIDSEARCH ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__C': 10.01}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.936046511627907"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logregpipe = Pipeline([('scale', StandardScaler()),\n",
    "                   ('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "\n",
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'logreg__C':np.arange(0.01,100,10)}\n",
    "logreg_cv = GridSearchCV(logregpipe,param_grid,cv=5,return_train_score=True)\n",
    "logreg_cv.fit(X,y_under_train)\n",
    "print(logreg_cv.best_params_)\n",
    "\n",
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X,y_under_train)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X,y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIDSEARCH ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9324324324324325"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X2,y_under_test)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X2,y_under_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9287790697674418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predicted = cross_validation.cross_val_predict(LogisticRegression(),X,y_under_train, cv=10)\n",
    "print (metrics.accuracy_score(y_under_train, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92       149\n",
      "          1       0.95      0.88      0.91       147\n",
      "\n",
      "avg / total       0.92      0.92      0.92       296\n",
      "\n",
      "0.9155405405405406\n"
     ]
    }
   ],
   "source": [
    "predicted1 = cross_validation.cross_val_predict(LogisticRegression(),X2, y_under_test, cv=10)\n",
    "\n",
    "print (metrics.classification_report(y_under_test, predicted1))\n",
    "print (metrics.accuracy_score(y_under_test, predicted1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K BEST ON NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores_: [1.65592843e+02 2.20551955e+02 3.43212801e+02 6.72683958e+02\n",
      " 1.19196109e+02 1.42737958e+02 2.25752047e+02 6.13275884e+00\n",
      " 2.79631571e+02 4.88209223e+02 5.96432541e+02 6.58021075e+02\n",
      " 2.14225592e-01 8.94099051e+02 4.44519587e+00 3.55217940e+02\n",
      " 3.20498725e+02 1.87876037e+02 6.41033839e+01 1.75695938e+01\n",
      " 2.05682869e+01 2.89655486e-01 1.64784613e+00 7.69941297e+00\n",
      " 9.43310591e-01 1.31281455e+00 1.00674815e+01 5.98782855e+00\n",
      " 7.68106861e+00]\n",
      "pvalues_: [4.22895241e-034 1.82849968e-043 1.95313906e-062 6.84189115e-104\n",
      " 1.07097431e-025 5.06567685e-030 2.54854459e-044 1.35100597e-002\n",
      " 6.60753346e-053 4.07170712e-082 2.83440166e-095 2.84402820e-102\n",
      " 6.43622181e-001 2.07605403e-126 3.53615968e-002 3.61676986e-064\n",
      " 4.21702811e-059 5.71496554e-038 5.05654966e-015 3.13237129e-005\n",
      " 6.79095430e-006 5.90615958e-001 1.99685763e-001 5.67423525e-003\n",
      " 3.31770215e-001 2.52285232e-001 1.57644943e-003 1.46547547e-002\n",
      " 5.73154676e-003]\n",
      "selected index: [ 2  3  6  8  9 10 11 13 15 16]\n",
      "after transform: [[-4.46825973  2.80533626 -4.2612372  ... -7.41771206 -3.65280196\n",
      "  -6.29314532]\n",
      " [-0.15338691  1.54666597  0.66024094 ...  0.23399072 -0.65630523\n",
      "   0.14325206]\n",
      " [-1.78708524  1.2151043   0.53676488 ...  0.83471796 -0.39377439\n",
      "  -0.48678703]\n",
      " ...\n",
      " [-0.57078722 -1.35746676  0.07137438 ...  0.39310706 -0.50867175\n",
      "  -0.40023883]\n",
      " [-3.07095919  1.56081585  1.65930762 ...  1.4670155  -0.47624902\n",
      "  -0.46548497]\n",
      " [-1.91185118  0.19399166 -0.15471662 ... -1.59418955 -0.87897415\n",
      "   2.00665858]]\n"
     ]
    }
   ],
   "source": [
    "array = under_sample.values\n",
    "test = SelectKBest(score_func=f_classif,k=10)\n",
    "fit = test.fit(X_under_train, y_under_train)\n",
    "print(\"scores_:\",test.scores_)\n",
    "print(\"pvalues_:\",test.pvalues_)\n",
    "print(\"selected index:\",test.get_support(True))\n",
    "print(\"after transform:\",test.transform(X_under_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[337   6]\n",
      " [ 47 298]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93       343\n",
      "          1       0.98      0.86      0.92       345\n",
      "\n",
      "avg / total       0.93      0.92      0.92       688\n",
      "\n",
      "0.9229651162790697\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "X = X_under_train[['V2','V3','V4','V9','V10','V11','V12','V14','V16','V17']]\n",
    "gnb.fit(X,y_under_train)\n",
    "y_pred = gnb.predict(X)\n",
    "print(confusion_matrix(y_under_train,y_pred))  \n",
    "print(classification_report(y_under_train,y_pred))\n",
    "print(accuracy_score(y_under_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148   1]\n",
      " [ 23 124]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.99      0.92       149\n",
      "          1       0.99      0.84      0.91       147\n",
      "\n",
      "avg / total       0.93      0.92      0.92       296\n",
      "\n",
      "0.918918918918919\n"
     ]
    }
   ],
   "source": [
    "X2 = X_under_test[['V2','V3','V4','V9','V10','V11','V12','V14','V16','V17']]\n",
    "y_pred = gnb.predict(X2)\n",
    "print(confusion_matrix(y_under_test,y_pred))  \n",
    "print(classification_report(y_under_test,y_pred))\n",
    "print(accuracy_score(y_under_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIDSEARCH ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__C': 10.01}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9433139534883721"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logregpipe = Pipeline([('scale', StandardScaler()),\n",
    "                   ('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "\n",
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'logreg__C':np.arange(0.01,100,10)}\n",
    "logreg_cv = GridSearchCV(logregpipe,param_grid,cv=5,return_train_score=True)\n",
    "logreg_cv.fit(X,y_under_train)\n",
    "print(logreg_cv.best_params_)\n",
    "\n",
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X,y_under_train)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X,y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIDSEARCH ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956081081081081"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X2,y_under_test)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X2,y_under_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION ON TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predicted = cross_validation.cross_val_predict(LogisticRegression(),X,y_under_train, cv=10)\n",
    "print (metrics.accuracy_score(y_under_train, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       149\n",
      "          1       0.98      0.90      0.94       147\n",
      "\n",
      "avg / total       0.94      0.94      0.94       296\n",
      "\n",
      "0.9391891891891891\n"
     ]
    }
   ],
   "source": [
    "predicted1 = cross_validation.cross_val_predict(LogisticRegression(),X2, y_under_test, cv=10)\n",
    "\n",
    "print (metrics.classification_report(y_under_test, predicted1))\n",
    "print (metrics.accuracy_score(y_under_test, predicted1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA ON NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.93521210e-01 4.44591830e-03 5.59561879e-04 5.26170173e-04\n",
      " 2.42045617e-04]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "X_under_train = pca.fit_transform(X_under_train)\n",
    "X_under_test = pca.transform(X_under_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL FITTING ON TRAIN & TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144   5]\n",
      " [ 20 127]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       149\n",
      "          1       0.96      0.86      0.91       147\n",
      "\n",
      "avg / total       0.92      0.92      0.92       296\n",
      "\n",
      "0.9155405405405406\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_under_train,y_under_train)\n",
    "y_pred = gnb.predict(X_under_test)\n",
    "print(confusion_matrix(y_under_test,y_pred))  \n",
    "print(classification_report(y_under_test,y_pred))\n",
    "print(accuracy_score(y_under_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIDSEARCH ON TEST & TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg__C': 10.01}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logregpipe = Pipeline([('scale', StandardScaler()),\n",
    "                   ('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "\n",
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'logreg__C':np.arange(0.01,100,10)}\n",
    "logreg_cv = GridSearchCV(logregpipe,param_grid,cv=5,return_train_score=True)\n",
    "logreg_cv.fit(X_under_train,y_under_train)\n",
    "print(logreg_cv.best_params_)\n",
    "\n",
    "bestlogreg = logreg_cv.best_estimator_\n",
    "bestlogreg.fit(X_under_train,y_under_train)\n",
    "bestlogreg.coef_ = bestlogreg.named_steps['logreg'].coef_\n",
    "bestlogreg.score(X_under_train,y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION ON TEST & TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934593023255814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predicted = cross_validation.cross_val_predict(LogisticRegression(),X_under_train,y_under_train, cv=10)\n",
    "print (metrics.accuracy_score(y_under_train, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93       149\n",
      "          1       0.98      0.88      0.92       147\n",
      "\n",
      "avg / total       0.93      0.93      0.93       296\n",
      "\n",
      "0.9290540540540541\n"
     ]
    }
   ],
   "source": [
    "predicted1 = cross_validation.cross_val_predict(LogisticRegression(),X_under_test, y_under_test, cv=10)\n",
    "\n",
    "print (metrics.classification_report(y_under_test, predicted1))\n",
    "print (metrics.accuracy_score(y_under_test, predicted1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
